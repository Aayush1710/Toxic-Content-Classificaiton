# Toxic-Content-Classificaiton

Our project, is based on a kaggle competition, and aims towards detection of toxic comments on Wikipedia. Weâ€™ll be experimenting using variants of naive bayes (NB) and Support vector machines (SVM) as baseline methods for toxic text classification, but since their performance varies greatly depending on the model variant, features used and task/ dataset, we then will create deep neural network model to detect various subtleties of toxicities in the dataset. We show that the inclusion of word bigram features gives consistent gains on sentiment analysis tasks for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents, it's the other way round). Based on such observations, we aim to compare the scores for very strong non-neural network models  and deep architectures to parameterize when each of those perform better. To contribute, we plan to improve the F! Score and provide an efficient algorithm to detect toxic comments on Wikipedia.
